{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Recorrente (RNN) \n",
    "\n",
    "Neste notebook nós treinamos uma RNN em algumas músicas da Anitta. Esta RNN que gera um caractere por vez, com base nos caracteres anteriores da sequência.\n",
    "\n",
    "O código original da RNN foi escrito por por [vinhkhuc](https://gist.github.com/vinhkhuc/7ec5bf797308279dc587), baseado no código de Andrej Karpathy (atualmente diretor de IA da Tesla Motors).\n",
    "O código foi modificado por Peterson Zilli para atender por um número máximo de iterações e ler caracteres utf-8.\n",
    "\n",
    "Usamos esta RNN para gerar funk a partir do treinamento com as 15 músicas mais acessadas da Anitta que retiramos do site [letras.com.br](www.letras.com.br).\n",
    "\n",
    "As letras estão no arquivo 'anitta.txt'\n",
    "\n",
    "Vinicius F. Caridá & Amir Jalilifard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você prepara, mas não dispara\n",
      "Você repara, mas não encara\n",
      "Se acha o cara, mas não me para\n",
      "Tá cheio de maldade, mas não me encara\n",
      "\n",
      "Você já tá querendo e eu também\n",
      "Mas é cheio de história e de porém\n",
      "Virou covarde, tô com vontade\n",
      "Mas você tá demorando uma eternidade\n",
      "\n",
      "Se você não vem, eu vou botar pressão\n",
      "Não vou te esperar, tô cheia de opção\n",
      "Eu não sou mulher de aturar sermão\n",
      "Me encara, se prepara\n",
      "Que eu vou jogar bem na sua cara\n",
      "\n",
      "Bem na sua cara\n",
      "Eu vou rebolar bem na sua cara\n",
      "Bem na sua cara\n",
      "Hoje \n"
     ]
    }
   ],
   "source": [
    "with open('anitta.txt', 'r', encoding='utf-8') as txt:\n",
    "    print(txt.read(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, usamos este texto para treinar a rede recorrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 7174 characters, 65 unique.\n",
      "WARNING:tensorflow:From C:\\Users\\vinicius\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-47c366aa9e92>:57: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "iter: 0, p: 0, loss: 4.652970\n",
      "----\n",
      " :moÔrãé\n",
      "roãHçQ?zUUftô\"ãoj::êá\"??v,kãJMeéBRézHMUSxEH t VFqmEçqkQDxa\n",
      "qÉãt:t:Qiíré,SúIUCl-éafMUAvNBA,)dzA\n",
      "chCteujCQ,pN \n",
      "B,vJtDQsó?zFàTcãTkleOie o)ÔãEJ\"NRkqé)JEuêMkH:Fíkc,E,Hm,uípãElEví:ôçdPf,b?)(kJ-ot-úx \n",
      "----\n",
      "\n",
      "iter: 500, p: 5350, loss: 3.267852\n",
      "----\n",
      " iBa lDuhael oladadi veutlh,ld daEdrlôda jqaeo deuarL,rdaa eEr q qdiMgt, ern sounpleeieluv nlara,rardirterele el çlim\n",
      "a\n",
      "i,ue dsmazeElffhru evnaa dvde aoiteE\n",
      "duaere\n",
      "ev dode cu, lu  releSfe ernhbesl, nee \n",
      "----\n",
      "\n",
      "iter: 1000, p: 3550, loss: 2.557410\n",
      "----\n",
      " ebnsa, caq, menhmm, nor vmlt\n",
      "Nor no sueroroo: decMra V\n",
      ", ha tu \n",
      "uu ,u tum\n",
      "\n",
      "uar oejsua, uã u peuc,\n",
      "resendinE\n",
      ", g n u , viuUu, uh, um\n",
      "luh, mrduobQpãe ôn sv:mu tou uraH\n",
      "\n",
      "Si ue  uindi\n",
      "\n",
      "Equo cu\n",
      "\n",
      "ua,:, usu  \n",
      "----\n",
      "\n",
      "iter: 1500, p: 1750, loss: 2.566121\n",
      "----\n",
      " ma\n",
      "\n",
      "né nusêMaoa\n",
      "Deita ãisterhaito vei teisne nfrtetsnttô nomg)mR\n",
      "oulterv\n",
      "Semsmeidine\n",
      ", e ndacemnn o eo eadelte eiu qua de soe nmipaepô deu , nconãetimiita\n",
      "môita nu tenão diterNsontamenaHrenfea dua em  \n",
      "----\n",
      "\n",
      "iter: 2000, p: 7100, loss: 2.355160\n",
      "----\n",
      " ciu fep drrimone emo caita com fe e cêO, o fedonque lmibo ter elo seu eue que ces fracor queno ela-pê  hiz a E mer quima lascona à fea, e te voish, lav e mãi er nm nes o cer\n",
      "o ioevau rS nhema, pa tem  \n",
      "----\n",
      "\n",
      "iter: 2500, p: 5300, loss: 2.397562\n",
      "----\n",
      "  no bos emina éu, dem  ão vodê \n",
      "Los u, euna dipai\n",
      "nuib e noubasu, esoUte a sendin\n",
      "Dendo ca u minha e, iô ein, vosta, esacandoe ja rando\n",
      "eu, e  nmi:Ua\n",
      "Misa tereu, dontir\n",
      "oe você\n",
      "\n",
      "Eusa tristonco\n",
      "Quh che \n",
      "----\n",
      "\n",
      "iter: 3000, p: 3500, loss: 1.388788\n",
      "----\n",
      " oãa éão  ou ro tarar far nh a tasia arode e ne vou Co tana\n",
      "\n",
      "Te an\n",
      "íapcar\n",
      "Eita tua o facHade, não ue po ai, fom e e u venão\n",
      "Da eu tavaca\n",
      "Cão vom quh\n",
      "Dovo\n",
      "\n",
      "Eup, dom teno beipado\n",
      "Mom tat\n",
      "\n",
      "Qoco des\n",
      "Tegohe \n",
      "----\n",
      "\n",
      "iter: 3500, p: 1700, loss: 2.666428\n",
      "----\n",
      " eitar, no sueronto mumi\n",
      "\n",
      "Qussom mam nidanhontosa merar, tinhe não emtemda, emCemtitemer\n",
      "Da urca sm qnessar ensinão\n",
      "Vão mom\n",
      "SBam não mrutr  emo\n",
      "Nna miu ssarina tenmise mão mm masint volpontão voo rão\n",
      "M \n",
      "----\n",
      "\n",
      "iter: 4000, p: 7050, loss: 1.552294\n",
      "----\n",
      " r e gim a Bum c\n",
      "Emo ces vidad:\n",
      "Meb noelo\n",
      "Meluãom jlamir vo vento de  vivor, ere de fuze\n",
      "\n",
      "Tu paro quere ora mua, tes e mla varài, e que qur dur, com vida\n",
      "Se m áml: por você\n",
      "que ne cunto pela\n",
      "\n",
      "u vem das \n",
      "----\n",
      "\n",
      "iter: 4500, p: 5250, loss: 1.915155\n",
      "----\n",
      " é noito er eu rrem jecente manbe\n",
      "\n",
      "Qunão Codi so, e ntero\n",
      "Beje\n",
      "Não\n",
      "boi a er que quinde que dena\n",
      "Navec\n",
      "\n",
      "Mesfa tencorelai e escorne jeda, ela conta\n",
      "Vome ne so e vori sor co, essa vei cando pida tue a\n",
      "Mij \n",
      "----\n",
      "\n",
      "iter: 5000, p: 3450, loss: 0.215192\n",
      "----\n",
      "  voca\n",
      "Dvima, nlvanh\n",
      "anhas nm uri bra cem nivai que m ntefse\n",
      "Qu gou o tão ena boixa comina\n",
      "\n",
      "reitam não mam vem sse cartam vec (mro, eucantão cog ão nhobea cob em vocêra, nassiravam não quir\n",
      "Dereu tô ca \n",
      "----\n",
      "\n",
      "iter: 5500, p: 1650, loss: 2.425748\n",
      "----\n",
      " memorinroptemprop\n",
      "Pe mivarobamaco cinaa\n",
      "\n",
      "Bôm ga ssemeu sou querma sa felater, desroues arasa\n",
      "Veido quetmodevgo tesotem ogarta cara\n",
      "Hojentoso sso vou ao tomentere uerelhertiuprrapé\n",
      "tômprraçho fezerea\n",
      "V \n",
      "----\n",
      "\n",
      "iter: 6000, p: 7000, loss: 1.836153\n",
      "----\n",
      " t\n",
      "Ela suvrim nmo você\n",
      "Eu quero cemporem nu mruç, a a elo Tua suare  e velto eu te ero dato qua fei o cemprr vri cá me entem eis\n",
      "E lodo tá esthe e mocê\n",
      "Eu quero te poica\n",
      "Es que\n",
      "Eu canvouch\n",
      "Lo s o conco \n",
      "----\n",
      "\n",
      "iter: 6500, p: 5200, loss: 2.083967\n",
      "----\n",
      " oca\n",
      "Se é molh, e so te min\n",
      "Ela\n",
      "\n",
      "Queno que e você sobolo\n",
      "Se eu foven, ne o vider ba você\n",
      "Se eu tim cana cer ei\n",
      "Vecanje eu quiro cominha mila é ló com é bonaa sovaço\n",
      "\n",
      "Tento genda, eu tantinar e co paico \n",
      "----\n",
      "\n",
      "iter: 7000, p: 3400, loss: 1.072202\n",
      "----\n",
      "  sendoda\n",
      "Deino socar ge tiro cebaç,\n",
      "E dentessa\n",
      "\n",
      "Vanto pra vque ioupção, eissei que sorra\n",
      "Vore e seçvoccado, aqucena éupra\n",
      "\n",
      "Ae mate chata ei, vão\n",
      "ção a vacmeqde a vúlta\n",
      "Daras te cemem\n",
      "Sar ar veu quecgo \n",
      "----\n",
      "\n",
      "iter: 7500, p: 1600, loss: 2.036503\n",
      "----\n",
      " Uh, uh, uh, era\n",
      "E puatvocê\n",
      "pram\n",
      "Do que cara, mispam não\n",
      "O émufecoraldasso que de ela murim\n",
      "E compremolojo entris\n",
      "Mec fe ompra euar se jestira meu te tor de tão seu snaros, tô locar\n",
      "Es á mins se vou jo \n",
      "----\n",
      "\n",
      "iter: 8000, p: 6950, loss: 1.285914\n",
      "----\n",
      " vo mim veisser aro sou seu deina\n",
      "Eu tomo que eu voupreLer o monce pro você pento do gem rocar\n",
      "\n",
      "E ero assammis tem io quero trm prafrade ero e frch\n",
      "\n",
      "E você o tóir, mim\n",
      "isos dem\n",
      "Elsa esia cem e com fiz\n",
      " \n",
      "----\n",
      "\n",
      "iter: 8500, p: 5150, loss: 0.404757\n",
      "----\n",
      " ocê mainaobom\n",
      "Vadei\n",
      "E não mocae\n",
      "Pome tãoqueseu lola quarabpide ecané sea\n",
      "Eu gobalquer\n",
      "Dem tetiSimaDolta\n",
      "Elada é oa cina beprascodaim de vadejoa mança, livape\n",
      "Tãe moua, nos a émro\n",
      "Eu a lora é loina por \n",
      "----\n",
      "\n",
      "iter: 9000, p: 3350, loss: 0.481098\n",
      "----\n",
      " o\n",
      "Eloucar não paração fela\n",
      "E\n",
      "pinha cando pra vido\n",
      "E pei sim\n",
      "\n",
      "Uh, chiso grque crim\n",
      "Sem não\n",
      "\n",
      "E mes se você se veca malicor\n",
      "Tão campinzera\n",
      "\n",
      "Eu tulra pre encosacmidicar nara vem, etura, se passia pra mes\n",
      " \n",
      "----\n",
      "\n",
      "iter: 9500, p: 1550, loss: 0.899345\n",
      "----\n",
      "  o sora, não não bem te pore tor au selver vompna bocê pravou jou jo vesate no soce\n",
      "Se e oo vou jegente praterana eja caram ou jolto pre aque vabesso você mandeso asso sem dua peraper o panto sam não  \n",
      "----\n",
      "\n",
      "iter: 10000, p: 6900, loss: 1.340096\n",
      "----\n",
      "  e fez o cerro mssum ua minta repoita\n",
      "Cejo quentari\n",
      "Eu a tello\n",
      "Ar do er da mapra asumo à mande ra perto tão pele\n",
      "O raro temrina\n",
      "Melha masNadaspar amoo semro, mem\n",
      "lohocr\n",
      "Me eu monTe fai\n",
      "\n",
      "Eu que o compr \n",
      "----\n",
      "\n",
      "iter: 10500, p: 5100, loss: 0.084051\n",
      "----\n",
      " ira a minha rabit, ta du mim\n",
      "Se e você\n",
      "\n",
      "E eu tô bom feilo fai\n",
      "\n",
      "Eu a mio\n",
      "E temin\n",
      "Quenco qua mina é couta\n",
      "Que comúmalo qum não voue terem\n",
      "\n",
      "Megea ssa é faitar\n",
      "Quem ondo mantada\n",
      "Qua a alãi\n",
      "Segocolancoca\n",
      "É \n",
      "----\n",
      "\n",
      "iter: 11000, p: 3300, loss: 1.047555\n",
      "----\n",
      " jo nis você\n",
      "A secotaca pracor\n",
      "livo sr vica\n",
      "Quag bel\n",
      "Te dessse cortçe você quanda, ces meu cara com arastam você ceschra, sua comprncar inpor mis\n",
      "ó mino são mer de ma ges prao ter veu caraçchis\n",
      "\n",
      "Uh, eh \n",
      "----\n",
      "\n",
      "iter: 11500, p: 1500, loss: 1.116354\n",
      "----\n",
      " bossó mopre armais\n",
      "Mes a ceraz re eu vira ata Je vor jo pre ple vicar, etaro cum velas\n",
      "Elam o antrra m sinter aatsaim\n",
      "Des se rna ém vaco tô prembocana bom quenda em tô bem que sou ara\n",
      "\n",
      "Vácê propara do \n",
      "----\n",
      "\n",
      "iter: 12000, p: 6850, loss: 1.388283\n",
      "----\n",
      " az ndo da a vocantrri, el cqu so e teino comas\n",
      "Te dizenco, mosto dona que muma\n",
      "Pemanco amo te dei a cê to da de aim não de anCanvoa canvo co meja\n",
      "E sea mina é laia peras o vom te o ima es a meja\n",
      "Me te \n",
      "----\n",
      "\n",
      "iter: 12500, p: 5050, loss: 0.069853\n",
      "----\n",
      " ue safa dade\n",
      "Se eu to bomua sorocarazesta dasa a moca\n",
      "Se acora quer, essumrou fente em faço cumiose: Você é mantada e cometerfacurta que comafasta\n",
      "Niroa moila mou contandado dera ita telhareja\n",
      "Vamose  \n",
      "----\n",
      "\n",
      "iter: 13000, p: 3250, loss: 1.251046\n",
      "----\n",
      " ere eivocê é felto que sabomandemela\n",
      "Eue eu daspr:pompoúha cem você cim\n",
      "Se você\n",
      "mão costocar neu fentavendade que gardode\n",
      "\n",
      "Uão que emina\n",
      "\n",
      "Eunvou bogar me vacgo, você\n",
      "Mesnarando colho vogê\n",
      "\n",
      "Loncaro\n",
      "Mes \n",
      "----\n",
      "\n",
      "iter: 13500, p: 1450, loss: 1.036454\n",
      "----\n",
      " pra ata Bei a mmar é você tua a me melei\n",
      "po que vir, passsai aá enurr, ue onão\n",
      "rem na sua cara\n",
      "Se acha ge anno arasque se émopra bemana nuasse veraco arapararQuar va  urapar\n",
      "\n",
      "Bem ua sua cara\n",
      "Hojesel d \n",
      "----\n",
      "\n",
      "iter: 14000, p: 6800, loss: 1.378381\n",
      "----\n",
      " \n",
      "Te dar: Bombé aúra a am ni do, Pontfa\n",
      "Roi\n",
      "Eu a voco\n",
      "Ma belte er asor, cra am fra se fiz se teva\n",
      "Masoi\n",
      "Ta garte reballa Diis\n",
      "\n",
      "Vicandessinas\n",
      "Vá dis\n",
      "Hocêm\n",
      "Te quero afaz me é te oca, melh, feitatcompsojr \n",
      "----\n",
      "\n",
      "iter: 14500, p: 5000, loss: 0.088952\n",
      "----\n",
      " ebem, tes vacê te palintr de onher\n",
      "Tem você te es quene ferda, mar é sum ina to que seréço\n",
      "Mi baide eu teveltão temjandia cang)i ter eu quero amanala\n",
      "Bem dava vemmindo\n",
      "Não cosse:jo\n",
      "Mas mem da minda\n",
      "Ci \n",
      "----\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 15000, p: 3200, loss: 0.616960\n",
      "----\n",
      " \n",
      "Uh, uh, uh, uh\n",
      "\n",
      "Eu a gosaç\n",
      "\n",
      "Eu vou covar begene sossenvade padque são nãssó você é pórizam\n",
      "\n",
      "Te você que salim\n",
      "\n",
      "E vai so vaz rasera s ancinar eltocar ndo que cardidadisiro se você\n",
      "Ana beger o possãa q \n",
      "----\n",
      "\n",
      "iter: 15500, p: 1400, loss: 1.026774\n",
      "----\n",
      " pra daz repara do gasbam\n",
      "\n",
      "Ves ue minda vinde eu tambou me te campramo possa dize eu te cara\n",
      "Vom erala, nassou pentaro\n",
      "Me moila do dizere felum, era poca\n",
      "Lenda diupremomico eua cuatvada\n",
      "Vom qua ae e pr \n",
      "----\n",
      "\n",
      "iter: 16000, p: 6750, loss: 0.491797\n",
      "----\n",
      " m cancos debola de aca\n",
      "Bassa mupri tô dadinde Omo ê cao e nto lou e dea pecêita candiP r ua olhara, jovele conte (mo êuca, esse reucarelo que é fadi, cê-ra, uss elenta cBem\n",
      "Eu vou jora, Pocê já tô bem \n",
      "----\n",
      "\n",
      "iter: 16500, p: 4950, loss: 0.013801\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-47c366aa9e92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0msample_output_softmax_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_prev_state_val\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 sess.run([output_softmax, hprev],\n\u001b[1;32m--> 114\u001b[1;33m                          feed_dict={inputs: sample_input_vals, init_state: sample_prev_state_val})\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_output_softmax_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Vanilla Char-RNN using TensorFlow by Vinh Khuc (@knvinh).\n",
    "Adapted from Karpathy's min-char-rnn.py\n",
    "https://gist.github.com/karpathy/d4dee566867f8291f086\n",
    "Requires tensorflow>=1.0\n",
    "BSD License\n",
    "\"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "seed_value = 42\n",
    "tf.set_random_seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "def one_hot(v):\n",
    "    return np.eye(vocab_size)[v]\n",
    "\n",
    "# Data I/O\n",
    "data = open('anitta.txt', 'r', encoding='utf-8').read()  # Use this source file as input for RNN\n",
    "chars = sorted(list(set(data)))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('Data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
    "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "# Hyper-parameters\n",
    "hidden_size   = 256  # hidden layer's size\n",
    "seq_length    = 25   # number of steps to unroll\n",
    "learning_rate = 1e-3\n",
    "\n",
    "inputs     = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name=\"inputs\")\n",
    "targets    = tf.placeholder(shape=[None, vocab_size], dtype=tf.float32, name=\"targets\")\n",
    "init_state = tf.placeholder(shape=[1, hidden_size], dtype=tf.float32, name=\"state\")\n",
    "\n",
    "initializer = tf.random_normal_initializer(stddev=0.1)\n",
    "\n",
    "with tf.variable_scope(\"RNN\") as scope:\n",
    "    hs_t = init_state\n",
    "    ys = []\n",
    "    for t, xs_t in enumerate(tf.split(inputs, seq_length, axis=0)):\n",
    "        if t > 0: scope.reuse_variables()  # Reuse variables\n",
    "        Wxh = tf.get_variable(\"Wxh\", [vocab_size, hidden_size], initializer=initializer)\n",
    "        Whh = tf.get_variable(\"Whh\", [hidden_size, hidden_size], initializer=initializer)\n",
    "        Why = tf.get_variable(\"Why\", [hidden_size, vocab_size], initializer=initializer)\n",
    "        bh  = tf.get_variable(\"bh\", [hidden_size], initializer=initializer)\n",
    "        by  = tf.get_variable(\"by\", [vocab_size], initializer=initializer)\n",
    "\n",
    "        hs_t = tf.tanh(tf.matmul(xs_t, Wxh) + tf.matmul(hs_t, Whh) + bh)\n",
    "        ys_t = tf.matmul(hs_t, Why) + by\n",
    "        ys.append(ys_t)\n",
    "\n",
    "hprev = hs_t\n",
    "output_softmax = tf.nn.softmax(ys[-1])  # Get softmax for sampling\n",
    "\n",
    "outputs = tf.concat(ys, axis=0)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=targets, logits=outputs))\n",
    "\n",
    "# Minimizer\n",
    "minimizer = tf.train.AdamOptimizer()\n",
    "grads_and_vars = minimizer.compute_gradients(loss)\n",
    "\n",
    "# Gradient clipping\n",
    "grad_clipping = tf.constant(5.0, name=\"grad_clipping\")\n",
    "clipped_grads_and_vars = []\n",
    "for grad, var in grads_and_vars:\n",
    "    clipped_grad = tf.clip_by_value(grad, -grad_clipping, grad_clipping)\n",
    "    clipped_grads_and_vars.append((clipped_grad, var))\n",
    "\n",
    "# Gradient updates\n",
    "updates = minimizer.apply_gradients(clipped_grads_and_vars)\n",
    "\n",
    "# Session\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "# Initial values\n",
    "n, p = 0, 0\n",
    "hprev_val = np.zeros([1, hidden_size])\n",
    "\n",
    "while True:\n",
    "    # Initialize\n",
    "    if p + seq_length + 1 >= len(data) or n == 0:\n",
    "        hprev_val = np.zeros([1, hidden_size])\n",
    "        p = 0  # reset\n",
    "\n",
    "    # Prepare inputs\n",
    "    input_vals  = [char_to_ix[ch] for ch in data[p:p + seq_length]]\n",
    "    target_vals = [char_to_ix[ch] for ch in data[p + 1:p + seq_length + 1]]\n",
    "\n",
    "    input_vals  = one_hot(input_vals)\n",
    "    target_vals = one_hot(target_vals)\n",
    "\n",
    "    hprev_val, loss_val, _ = sess.run([hprev, loss, updates],\n",
    "                                      feed_dict={inputs: input_vals,\n",
    "                                                 targets: target_vals,\n",
    "                                                 init_state: hprev_val})\n",
    "    if n % 500 == 0:\n",
    "        # Progress\n",
    "        print('iter: %d, p: %d, loss: %f' % (n, p, loss_val))\n",
    "\n",
    "        # Do sampling\n",
    "        sample_length = 200\n",
    "        start_ix      = random.randint(0, len(data) - seq_length)\n",
    "        sample_seq_ix = [char_to_ix[ch] for ch in data[start_ix:start_ix + seq_length]]\n",
    "        ixes          = []\n",
    "        sample_prev_state_val = np.copy(hprev_val)\n",
    "\n",
    "        for t in range(sample_length):\n",
    "            sample_input_vals = one_hot(sample_seq_ix)\n",
    "            sample_output_softmax_val, sample_prev_state_val = \\\n",
    "                sess.run([output_softmax, hprev],\n",
    "                         feed_dict={inputs: sample_input_vals, init_state: sample_prev_state_val})\n",
    "\n",
    "            ix = np.random.choice(range(vocab_size), p=sample_output_softmax_val.ravel())\n",
    "            ixes.append(ix)\n",
    "            sample_seq_ix = sample_seq_ix[1:] + [ix]\n",
    "\n",
    "        txt = ''.join(ix_to_char[ix] for ix in ixes)\n",
    "        print('----\\n %s \\n----\\n' % (txt,))\n",
    "\n",
    "    p += seq_length\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
